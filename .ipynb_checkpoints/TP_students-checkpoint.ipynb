{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP noté pour le cours d'Optimisation pour l'apprentissage\n",
    "\n",
    "\n",
    "Les trois premières parties de ce TP sont relativement simples, et portent sur la partie déterministe du cours. La quatrièeme et dernière partie, indépendante, est plus conséquente et porte sur la partie stochastique du cours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p hidden>Here are some Latex definitions</p> \n",
    "\n",
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\N}{\\mathcal{N}}$\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\E}{\\mathbb{E}}$\n",
    "$\\newcommand{\\Mm}{\\mathcal{M}}$\n",
    "$\\newcommand{\\Ll}{\\mathcal{L}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm, svd\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permet a une cellule d'avoir plus d'un display en sortie\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# Seed for np.random\n",
    "np.random.seed(seed=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Algorithme du gradient pour une fonction quadratique\n",
    "\n",
    "Etant donné $A$ une matrice symmétrique de $\\R^{N\\times N}$, et $b\\in \\R^N$, on cherche obtenir un vecteur minimisant la fonction\n",
    "\\begin{equation}\n",
    "f(x) = \\frac{1}{2}\\Vert Ax - b \\Vert^2.\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "On rappelle l'**Algorithme du Gradient à Pas Fixe** pour une fonction de gradient $L$-Lipschitzien:\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "|(GPF)| On choisit $x_0$ un vecteur de $\\R^N$ et $\\rho \\in ]0,2/L[$ un pas fixe. |\n",
    "|  | Pour $k\\geq 0$ : $x_{k+1}  = x_k  - \\rho \\nabla f(x_k)$. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici quelques commandes python dont vous pourrez avoir besoin:\n",
    "\n",
    "| | |\n",
    "|-|-|\n",
    "|`randn(m,n)`| Génère une matrice aléatoire dans $\\Mm_{m,n}(\\RR)$ |\n",
    "| `np.zeros((m,n))` | Génère une matrice nulle dans $\\Mm_{m,n}(\\RR)$ |\n",
    "| `np.ones((m,n))` | Génère une matrice remplie de $1$ dans $\\Mm_{m,n}(\\RR)$ |\n",
    "| `A.T` | Transposée de la matrice `A` |\n",
    "| `A@B` | Produit entre deux matrices |\n",
    "| `norm(A,2)` | Plus grande valeur singulière de `A` : $\\sigma_{min}(A)$ |\n",
    "| `norm(A,-2)` | Plus petite valeur singulière de `A` : $\\sigma_{max}(A)$ |\n",
    "| `norm(x)` | Norme Euclidienne du vecteur `x` |\n",
    "| `a = []` | Définit la liste vide `a` |\n",
    "| `a.append(18)` | Rajoute `18` à la fin de la liste `a` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Définir une matrice $A \\in \\Mm_{50,100}(\\RR)$, et un vecteur $y \\in \\RR^{50}$, tous deux alétoires. On utilisera la fonction `randn(m,n)` qui génère une matrice dans $\\Mm_{m,n}(\\RR)$ dont les coefficients suivent la loi normale centrée réduite. \n",
    "\n",
    "Ici, et durant toute la suite du TP, les **_vecteurs_** devront être considérés comme des matrices sous forme de vecteurs **_colonne_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = randn(50,100)\n",
    "y = randn(50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 100), dtype('float64'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((50,), dtype('float64'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.dtype\n",
    "y.shape, y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Rappel du cours/TD: Le gradient de la fonction $f$ en $x$ vaut $\\nabla f(x) = A^*(Ax-b)$ et $\\nabla^2 f(x) \\equiv A^*A$. Calculer $L$, la constante de Lipschitz du gradient de $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of f, using square of the norm of Ax-y\n",
    "def f(x, b):\n",
    "    return 1/2*math.pow(norm(A@x-b),2)\n",
    "\n",
    "def grad_f(A, x, b):\n",
    "    return A.T@(A@x-b)\n",
    "\n",
    "def gradsqr_f():\n",
    "    return A@A\n",
    "\n",
    "# Based on slide 8 of this pdf https://web.eecs.umich.edu/~fessler/course/598/l/n-03-gd.pdf\n",
    "# But I probably fucked up haha because this is obviously wrong\n",
    "L = norm(A*A, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.011714322208907"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1)** Définir une fonction `algo_gradient` qui:\n",
    "- prend en arguments une matrice `A`, un vecteur `b`, un point initial `x0`, un pas `rho`, et un nombre d'itérations maximal `itermax`\n",
    "- applique l'algorithme du gradient à pas constant à $f$, en partant de `x0`, pendant `itermax` itérations\n",
    "- renvoie le dernier itéré de la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally this function is correct\n",
    "def algo_gradient(A, b, x0, rho, itermax):\n",
    "    for i in range(itermax):\n",
    "        x = x0 - rho*grad_f(A, x0, b) \n",
    "        x0 = x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2)** Vérifier que votre fonction marche bien, en la testant avec $\\rho=1/L$, `nmax`$=10^3$ et un point initial de votre choix dans $\\RR^{100}$. Vous vérifierez également que la solution `x` ainsi obtenue satisfait $\\nabla f(x) \\simeq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.04340537e+00, -5.78032772e-01, -2.25861390e+00,  3.57807386e-01,\n",
       "        6.88404680e-01, -2.24557534e-01,  1.73866285e+00,  1.27095327e+00,\n",
       "       -3.13716094e-01,  1.07869974e+00,  8.61537061e-01, -2.07809608e-01,\n",
       "       -9.77592227e-01,  7.82014799e-01, -1.29256815e-01, -2.20715494e+00,\n",
       "        7.65187744e-01,  2.64863732e-01,  5.96275985e-01,  7.52049331e-01,\n",
       "       -1.65955728e+00,  1.00725961e+00, -1.28210668e+00,  7.80961003e-01,\n",
       "       -3.91160753e-01, -1.30090361e+00, -1.66947117e-01, -8.82087718e-01,\n",
       "        2.07811384e+00,  6.05949083e-01,  1.11946428e+00, -1.27294635e+00,\n",
       "       -4.10071540e-01, -6.38203339e-02, -9.10846436e-01,  6.40976837e-01,\n",
       "       -7.05531961e-01,  1.07996882e+00,  7.78264853e-01, -1.67216610e-01,\n",
       "        1.64059157e-01, -1.11546513e+00,  3.81649557e-01,  9.56041148e-01,\n",
       "        1.33017379e+00,  1.15588297e-01,  3.14216214e-01, -1.16158425e+00,\n",
       "       -1.67870180e+00,  8.55499796e-02,  4.91925203e-01,  2.23834063e+00,\n",
       "        1.30426928e+00, -1.15699492e-01, -8.88822677e-01,  6.49152848e-01,\n",
       "       -1.40938835e-01,  1.34664882e+00, -2.40479262e-01,  6.38200849e-01,\n",
       "       -1.50917599e+00,  3.07114799e-01, -8.14232649e-01,  5.92653842e-01,\n",
       "       -1.31429706e-03,  2.51870259e-01,  6.75950424e-02,  1.24400638e+00,\n",
       "        7.76956022e-01, -1.35233768e+00,  1.87060469e+00,  1.59445381e+00,\n",
       "        7.20577129e-01,  3.64988068e-02,  1.64548147e+00, -4.94534984e-01,\n",
       "        3.21701167e-01,  7.59177064e-02, -8.49414703e-01, -1.12244768e+00,\n",
       "        2.22803355e+00, -2.16297648e-01, -9.68602608e-01, -4.61665386e-01,\n",
       "        6.14790660e-01,  1.00416044e+00,  4.31931116e-01,  5.59105549e-01,\n",
       "       -2.63043484e-01, -7.44338075e-02,  1.11779088e+00,  1.47566352e+00,\n",
       "       -5.51629528e-01,  8.95257503e-01, -9.42562918e-01, -2.44588025e-01,\n",
       "        3.83946892e-01,  8.07499012e-01,  5.05687871e-02, -2.52487327e-01])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = randn(100,)\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fucking values go to infinity I dont know why\n",
    "x = algo_gradient(A, y, x0, 1/L, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25125606e+186,  2.27544868e+185,  2.06475396e+186,\n",
       "       -5.10252756e+185,  3.68007705e+186, -3.55174003e+186,\n",
       "        5.77610465e+186,  4.93681785e+186,  3.62755411e+186,\n",
       "       -4.37574452e+186,  1.90762207e+186,  2.51385857e+186,\n",
       "        1.35190279e+186,  4.52913769e+185,  2.17311577e+186,\n",
       "        3.22493338e+186,  4.34297710e+185,  2.06292144e+186,\n",
       "       -2.19264630e+186,  4.75526239e+186, -2.92610185e+186,\n",
       "       -3.13612129e+186, -8.00280918e+186, -7.83274924e+185,\n",
       "        2.25459667e+186, -1.91068190e+186,  5.19541306e+185,\n",
       "       -1.25509762e+186, -5.33815370e+185,  1.60012296e+186,\n",
       "       -4.63353219e+186, -2.20817667e+185, -7.96005643e+185,\n",
       "       -1.37604513e+186, -5.09758146e+186,  1.03496574e+185,\n",
       "        1.41857781e+186, -2.28199813e+186,  5.11696779e+186,\n",
       "        9.55678894e+184, -4.94336025e+186, -1.03004709e+186,\n",
       "        3.64115501e+186, -7.33700409e+184, -2.06547213e+186,\n",
       "        4.63541320e+186, -3.03590582e+186,  1.85291207e+186,\n",
       "       -3.00195062e+186, -4.83868196e+186, -3.57052148e+186,\n",
       "       -1.61635369e+186,  2.79506791e+186, -4.31308560e+185,\n",
       "       -5.17337676e+186, -1.05784188e+186,  5.18552981e+186,\n",
       "       -2.28246575e+186, -2.39496825e+186, -1.08545720e+186,\n",
       "       -3.52492457e+186,  3.29958897e+186,  7.38358342e+185,\n",
       "        3.80201199e+185, -4.83885857e+186,  2.84770582e+186,\n",
       "        6.11050479e+186,  6.50169490e+185,  3.70964940e+186,\n",
       "       -1.78245704e+186,  5.00117085e+186, -4.55637296e+186,\n",
       "        1.36550641e+186,  4.88736477e+186,  1.54846680e+186,\n",
       "       -5.90531407e+186,  2.19811139e+186, -1.19981651e+186,\n",
       "        7.80499814e+185,  8.45875655e+184, -1.74483850e+186,\n",
       "        3.31082166e+186,  2.06342482e+186, -2.44392898e+186,\n",
       "        6.60326264e+186, -3.22393278e+186, -6.54537386e+186,\n",
       "        1.49392753e+186, -1.13141765e+186, -2.56391994e+185,\n",
       "        6.25051057e+184,  2.72233577e+186,  2.44690786e+186,\n",
       "        3.85591576e+186, -2.97761916e+186, -1.18899862e+186,\n",
       "       -3.59616671e+186,  1.46460947e+186, -3.45793071e+184,\n",
       "        4.11588230e+186])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_f(A, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** On souhaite maintenant que l'algorithme aille le plus vite possible. Pour cela, on va se servir du cours, où on a vu que l'algorithme du gradient à pas fixe converge le plus vite lorsque $\\rho = \\frac{2}{\\mu+L}$, où $\\mu$ est la plus petite valeur singulière de $A^*A$.\n",
    "\n",
    "**4.1)** Calculer `mu` de deux façons différentes: $\\sigma_{min}(A^*A)$ et $\\sigma_{min}(A)^2$. Que constatez-vous? Lequel donne un résultat satisfaisant? A votre avis, pourquoi? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_1 = norm(A*A,-2)\n",
    "mu_2 = math.pow(norm(A,-2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.011714322208907, 8.870793367613173)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Havent really read which mu value is better normally I would think to bigger value is better\n",
    "# because we want a small step and a high mu value would reduce the fraction value\n",
    "mu_1, mu_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite, on gardera  `mu` comme étant le plus satisfaisant des deux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???\n",
    "mu = mu_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2)** Réécrire la fonction `algo_gradient` de telle manière qu'elle renvoie un nouveau second argument `values`, qui est une *liste* contenant toutes les valeurs $f(x^k)$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New version with evaluation of function\n",
    "def algo_gradient(A, b, x0, rho, itermax):\n",
    "    values = []\n",
    "    values.append(f(x0))\n",
    "    \n",
    "    for i in range(itermax):\n",
    "        x = x0 - rho*grad_f(A, x0, b) \n",
    "        x0 = x\n",
    "        values.append(f(x))\n",
    "    return x, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3)** Utiliser l'algorithme comme à la question **3.2)** en remplaçant le pas $1/L$ par $\\frac{2}{\\mu+L}$. Tracer la courbe $f(x^k)$ correspondante pour les deux choix de pas, et comparer.\n",
    "\n",
    "En pratique, lorsqu'on ne connait pas $\\mu$, il est conseillé de prendre comme pas $\\rho = \\beta/L$ avec $\\beta$ proche de $1.7\\sim 1.8$. Est-ce que cela marche bien sur cet exemple? Pourquoi à votre avis? Ce choix est-il équivalent à supposer quelque chose à propose de $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fucking values go to infinity I dont know why\n",
    "x_mu, values_mu = algo_gradient2(A, y, x0, 2/mu_2+L, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_beta, values_beta = algo_gradient2(A, y, x0, 1.7/L, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.42925369e+29, -1.17764142e+29,  7.10802335e+29, -6.75093985e+27,\n",
       "         1.22548233e+30, -7.98826829e+29,  1.57729528e+30,  1.95182816e+30,\n",
       "         1.07997575e+30, -1.49468509e+30,  6.88483348e+29,  1.37659275e+30,\n",
       "         2.58151030e+29,  7.66820548e+28,  6.21001752e+29,  8.41661436e+29,\n",
       "        -4.36678648e+29,  1.23173701e+30, -2.51404038e+28,  1.56576349e+30,\n",
       "        -1.11906396e+30, -9.50895910e+29, -3.33040985e+30, -1.06851573e+29,\n",
       "         3.18620585e+29, -7.06618757e+29, -2.10133317e+28, -3.03527498e+28,\n",
       "         1.46451373e+29,  9.17972552e+29, -9.45909860e+29,  5.57792970e+28,\n",
       "        -4.64983423e+29, -3.45853144e+29, -1.13553393e+30, -2.01321668e+29,\n",
       "        -6.56776695e+28, -3.96286018e+29,  1.77841146e+30, -2.33928598e+29,\n",
       "        -1.55938859e+30, -3.88946754e+29,  1.06600495e+30, -2.52060721e+29,\n",
       "        -3.31404836e+29,  9.32275132e+29, -1.04394109e+30,  7.34770104e+28,\n",
       "        -7.62168162e+29, -1.94221010e+30, -1.34106156e+30, -5.28658372e+29,\n",
       "         2.63824342e+29, -1.83543640e+29, -2.29652059e+30, -2.98526910e+29,\n",
       "         1.21222729e+30, -5.08837697e+29, -1.03791684e+30, -1.90383098e+29,\n",
       "        -6.51386877e+29,  1.01804331e+30,  2.36523954e+29,  6.31751296e+29,\n",
       "        -1.52280013e+30,  1.03981791e+30,  2.07878631e+30, -1.41317814e+29,\n",
       "         1.16381755e+30, -9.34979178e+29,  2.06568167e+30, -1.73806757e+30,\n",
       "         2.30020255e+29,  2.04133406e+30,  6.78986710e+29, -1.70247134e+30,\n",
       "         5.47158858e+29, -3.75770935e+29, -9.28535311e+28,  2.58195030e+29,\n",
       "        -7.03553938e+29,  7.76335090e+29,  3.64995203e+29, -8.20181830e+29,\n",
       "         1.64776283e+30, -1.21468256e+30, -1.78780853e+30,  4.63605414e+29,\n",
       "         6.54219637e+28, -4.87615510e+29,  2.39757461e+29,  1.28690276e+30,\n",
       "         7.89205187e+29,  1.73909597e+30, -1.21623914e+30, -3.75575782e+29,\n",
       "        -1.33133527e+30,  5.65529080e+29,  4.67199324e+29,  9.55593092e+29]),\n",
       " [2303.0885079269624,\n",
       "  1236370323.909801,\n",
       "  1243062363710105.8,\n",
       "  1.5185007620098016e+21,\n",
       "  1.9919365135287935e+27,\n",
       "  2.7017875035466087e+33,\n",
       "  3.739403429132772e+39,\n",
       "  5.250855804837222e+45,\n",
       "  7.456142161543775e+51,\n",
       "  1.0682079238938155e+58,\n",
       "  1.5412465104002186e+64])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mu, values_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.35205413e+19, -1.07699900e+19,  6.59897618e+19, -8.14156618e+17,\n",
       "         1.13864066e+20, -7.45542487e+19,  1.46843597e+20,  1.81029963e+20,\n",
       "         1.00411245e+20, -1.38866958e+20,  6.38859034e+19,  1.27337048e+20,\n",
       "         2.41588572e+19,  7.17133054e+18,  5.77067953e+19,  7.84583871e+19,\n",
       "        -4.00250602e+19,  1.13817744e+20, -2.93551548e+18,  1.45411452e+20,\n",
       "        -1.03753596e+20, -8.84175951e+19, -3.08757103e+20, -1.00609096e+19,\n",
       "         3.00055222e+19, -6.55758436e+19, -1.73084405e+18, -3.15347656e+18,\n",
       "         1.32275433e+19,  8.48266837e+19, -8.84493443e+19,  5.08361899e+18,\n",
       "        -4.29856995e+19, -3.22288931e+19, -1.06025846e+20, -1.84785445e+19,\n",
       "        -5.58783676e+18, -3.71857430e+19,  1.65129581e+20, -2.14123439e+19,\n",
       "        -1.44958778e+20, -3.61139607e+19,  9.92002370e+19, -2.31278184e+19,\n",
       "        -3.11356320e+19,  8.72246251e+19, -9.69264044e+19,  7.36870180e+18,\n",
       "        -7.10530210e+19, -1.80122702e+20, -1.24435371e+20, -4.91503361e+19,\n",
       "         2.51271630e+19, -1.69790655e+19, -2.12759968e+20, -2.78211063e+19,\n",
       "         1.13073813e+20, -4.74571902e+19, -9.61411555e+19, -1.78860867e+19,\n",
       "        -6.09643275e+19,  9.46197683e+19,  2.19703201e+19,  5.81808840e+19,\n",
       "        -1.41511797e+20,  9.64900735e+19,  1.93078698e+20, -1.28036293e+19,\n",
       "         1.08161461e+20, -8.65340642e+19,  1.91474628e+20, -1.61205998e+20,\n",
       "         2.15502676e+19,  1.89204901e+20,  6.29147886e+19, -1.58366186e+20,\n",
       "         5.09317102e+19, -3.49367574e+19, -8.31290968e+18,  2.37495901e+19,\n",
       "        -6.52652960e+19,  7.23767267e+19,  3.42646690e+19, -7.61425399e+19,\n",
       "         1.53572746e+20, -1.12747740e+20, -1.66380660e+20,  4.30877236e+19,\n",
       "         5.62048606e+18, -4.48766718e+19,  2.20899125e+19,  1.19141392e+20,\n",
       "         7.33304453e+19,  1.61094933e+20, -1.12744938e+20, -3.49113914e+19,\n",
       "        -1.23542945e+20,  5.24810122e+19,  4.29300237e+19,  8.92075402e+19]),\n",
       " [2303.0885079269624,\n",
       "  12102107.848486528,\n",
       "  120122371933.69223,\n",
       "  1447645663131225.2,\n",
       "  1.872288622337738e+19,\n",
       "  2.503232277169201e+23,\n",
       "  3.4149739730612704e+27,\n",
       "  4.726702108843907e+31,\n",
       "  6.615999959989599e+35,\n",
       "  9.343182458944309e+39,\n",
       "  1.3288221886333344e+44])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_beta, values_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# à compléter\n",
    "_ = plt.figure()\n",
    "_ = plt.yscale(\"log\")\n",
    "\n",
    "x, values = algo_gradient(A, y, x0, 1/L, 10)\n",
    "_ = plt.plot(values)\n",
    "x_mu, values_mu = algo_gradient(A, y, x0, 2/mu_2+L, 10)\n",
    "_ = plt.plot(values_mu)\n",
    "x_beta, values_beta = algo_gradient(A, y, x0, 1.75/L, 10)\n",
    "_ = plt.plot(values_beta)\n",
    "    \n",
    "_ = plt.legend([\"L\",\"Mu\", \"Beta\"]) # A modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Algorithme du gradient proximal\n",
    "\n",
    "Revenons au contexte du I. Nous avons vu que l'on pouvait minimiser $\\Vert Ax-b\\Vert^2$ avec l'algorithme du gradient, et donc résoudre l'équation $Ax=b$. Mais que peut-on dire de la solution que l'on a ainsi obtenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# N'exécuter cette cellule qu'une seule fois (prend un peu de temps) #\n",
    "######################################################################\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/Guillaume-Garrigos/invprob.git\n",
    "# python -m pip install git+https://github.com/Guillaume-Garrigos/invprob.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invprob import sparse\n",
    "from invprob.sparse import stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1)** Utiliser la fonction `sparse.randn` pour générer un vecteur $x_{origin}$ de $\\RR^{100}$ qui soit *parcimonieux* (*sparse* en VO), c'est-à-dire qui possède beaucoup de zéros. La fonction `stem` permet d'afficher les composantes de ce vecteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_composantes = 10\n",
    "x_origin = sparse.randn(100,1,nb_composantes)\n",
    "stem(x_origin)\n",
    "plt.title(\"Un beau signal bien parcimonieux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2)** Définir une matrice aléatoire $A \\in \\Mm_{50,100}(\\RR)$, et $b:=Ax_{origin}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3)** Utiliser l'algorithme du gradient du **I.**, pour calculer une solution du système linéaire $Ax=b$, que l'on notera `x_sol`.\n",
    "Utiliser `stem` pour visualiser si elle ressemble à `x_origin`. On utilisera un grand nombre d'itérations ($> 10^3$). Que constatez-vous? Est-ce que faire varier les paramètres de l'algorithme change quelque chose? Expliquer ce qui se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code pour tracer deux signaux x_origin et x_sol\n",
    "stem(x_origin, \"C0\")\n",
    "stem(x_sol, \"C1\")\n",
    "_=plt.legend([\"x_origin\",\"x_sol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Le système linéaire $Ax=b$ admet une infinité de solutions, ce qui est normal vu les dimensions de la matrice $A$. Cela veut donc dire que malgré $b=Ax_{origin}$, on ne pourra pas retrouver ce vecteur $x_{origin}$ en simplement minimisant $\\Vert Ax-b\\Vert^2$.\n",
    "\n",
    "Par contre il se trouve que parmi les solutions de $Ax=b$, $x_{origin}$ est certainement la solution la plus **parcimonieuse**, ce qui se traduit en général par le fait d'avoir une *faible norme L1* (voir figure ci-dessous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executer\n",
    "X, Y = [], []\n",
    "value_L1, value_L2 = [], []\n",
    "angles = np.arange(0, 2, 0.02)*np.pi\n",
    "for angle in angles:\n",
    "    x = np.cos(angle)\n",
    "    y = np.sin(angle)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    value_L1.append(np.abs(x)+np.abs(y))\n",
    "    value_L2.append(x**2 + y**2)\n",
    "\n",
    "_ = plt.figure(dpi=100)\n",
    "\n",
    "_ = plt.subplot(1, 2, 1)\n",
    "_ = plt.plot(X, Y, 'x')\n",
    "_ = plt.gca().set_aspect('equal')\n",
    "\n",
    "_ = plt.subplot(1, 2, 2)\n",
    "_ = plt.plot(angles, value_L1)\n",
    "_ = plt.plot(angles, value_L2)\n",
    "_ = plt.legend([\"L1\",\"L2\"])\n",
    "_ = plt.xticks([0, np.pi/2, np.pi, np.pi*3/2, 2*np.pi], ['0', '$\\\\frac{\\pi}{2}$', '$\\pi$', '$\\\\frac{3\\pi}{2}$', '$2\\pi$'])\n",
    "_ = plt.title('La norme L1 est minimale en les vecteurs parcimonieux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc il est raisonable de penser que $x_{origin}$ est de norme L1 minimale parmi les solutions de $Ax=b$. Autrement dit (et c'est une hypothèse raisonable), $x_{origin}$  est la solution du problème \n",
    "\n",
    "$$ \\min\\limits_{Ax=b} \\Vert x \\Vert_1.  $$\n",
    "\n",
    "Pour résoudre ce problème, on peut le *pénaliser*, c'est-à-dire introduire un paramètre $\\alpha>0$ petit, et résoudre:\n",
    "\n",
    "$$ \\min\\limits_{x} \\alpha \\Vert x \\Vert_1 + \\frac{1}{2}\\Vert Ax-b \\Vert^2. \\tag{$P_\\alpha$}$$\n",
    "\n",
    "\n",
    "On introduit l'**Algorithme du Gradient Proximal** pour la minimisation d'une fonction $f=g+h$ où $h$ est à gradient $L$-Lipschitzien et $g$ quelconque:\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "|(GP)| On choisit $x_0$ un vecteur de $\\R^N$ et $\\rho \\in ]0,2/L[$ un pas fixe. |\n",
    "|  | Pour $k\\geq 0$ : $x_{k+1}  = prox_{\\rho g} \\left(x_k  - \\rho \\nabla h(x_k)\\right)$. |\n",
    "\n",
    "où, pour une fonction $\\phi \\in \\Gamma_0(H)$, l'opérateur proximal $prox_\\phi : H \\rightarrow H$ est défini par:\n",
    "\n",
    "$$ prox_\\phi(x) := {\\rm{argmin}}_{x' \\in H}~\\phi(x') + \\frac{1}{2}\\Vert x-x' \\Vert^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invprob import prox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Pour tout réel $\\beta >0$, il est possible de calculer l'opérateur proximal de la fonction $\\beta \\Vert \\cdot \\Vert_1$ en un vecteur $x \\in \\mathbb{R}^N$, en utilisant la commande `prox.L1(X, beta)`.\n",
    "\n",
    "Tracer le graphe de la fonction $t \\mapsto prox_{\\vert \\cdot \\vert}(t)$ sur l'intervalle $[-2,2]$. Que constatez-vous lorsque $t \\in [-1,1]$? Quel impact pensez-vous que cela aura sur les itérés de l'algorithme du gradient proximal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Ecrire une fonction `algo_gradient_prox` qui \n",
    "- prend en arguments une matrice `A`, un vecteur `b`, un point initial `x0`, un pas `rho`, un nombre d'itérations maximal `itermax`, ainsi que le paramètre `alpha` apparaissant dans le problème $(P_\\alpha)$.\n",
    "- applique l'algorithme du gradient proximal à $f$ , en partant de `x0`, pendant `itermax` itérations. *(Faites **très** attention à qui est $g$ dans la définition de l'algorithme)*\n",
    "- renvoie le dernier itéré de la suite\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_gradient_prox(A, b, x0, rho, itermax, alpha):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** Utiliser cette fonction avec des petites valeurs pour `alpha` (entre 0.1 et 10) et visualiser le résultat comme précédemment. Commenter vos expériences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Le code qui suit devrait vous permettre d'avoir une visualisation interactive des solutions, en fonction du choix de `alpha`. \n",
    "Vous devrez compléter le code où c'est indiqué.\n",
    "\n",
    "(Pensez à vérifier que vous n'avez pas oublié l'installation requise au tout début du sujet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = norm(A.T@A,2)\n",
    "def widget_solution_l1(alpha): # calcule la solution du problème à alpha donné, et l'affiche\n",
    "    x_sol = algo_gradient_prox(# A COMPLETER\n",
    "    _ = plt.cla()\n",
    "    _ = plt.title(r\"Comparaison entre $x_{origin}$ et la solution $x_{sol}$ pour $\\alpha=$\" + str(np.ceil(alpha*100)/100))\n",
    "    _ = sparse.stem(x_origin, \"C0\")\n",
    "    _ = sparse.stem(x_sol, \"C1\")\n",
    "    _ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure()\n",
    "interactive(widget_solution_l1, \n",
    "            alpha=widgets.FloatLogSlider(min=-2, max=2, step=0.1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Application au traitement d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis Moodle, télécharger le fichier `photo.npy`, et le placer dans le même dossier que celui contenant ce notebook. Vous pourrez ensuite charger ce fichier comme une image dans python via la commande `np.load`, qui l'importe comme une matrice (dont les coefficients correspondent aux pixels) ; et l'afficher avec la commande `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'invprob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-738b7a55f632>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minvprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midct2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minvprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdotp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'invprob'"
     ]
    }
   ],
   "source": [
    "from invprob.signal import imread, imshow, gaussian_kernel, dct2, idct2\n",
    "from invprob.general import dotp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('photo.npy')\n",
    "imshow(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de cette section va être d'essayer de retirer l'effet de flou sur cette image, en la rendant plus nette.\n",
    "Pour cela nous allons simplement *modéliser* notre problème comme un problème inverse linéaire:\n",
    "- il existe une certaine image originale, notons-la $x$, que l'on voudrait récupérer.\n",
    "- cette image a subi un \"flou\", ce qui a abouti à l'image que l'on a téléchargé. Appelons cette image $b$.\n",
    "- l'opération de floutage est en fait une opération *linéaire* (on l'admet pour l'instant), donc on peut dire que $b=Ax$, où $A$ est l'application linéaire de floutage.\n",
    "- Pour retrouver $x$ à partir de $b$, il nous \"suffit\" donc de résoudre le système $Ax=b$, ce qui revient à minimiser $\\Vert Ax-b \\Vert^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Commençons par nous intéresser à cette application linéaire de floutage $A$, définie ci-dessous non pas comme une matrice mais via la fonction `flou()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executer cette cellule sans la modifier\n",
    "kernel_size = 3\n",
    "kernel_std = 1\n",
    "im_shape = (128,128)\n",
    "kernel_fourier = gaussian_kernel(kernel_size, kernel_std, im_shape)\n",
    "\n",
    "def flou(x): # La fonction qui permet d'évaluer A@x\n",
    "    return np.real(idct2(dct2(x) * kernel_fourier))\n",
    "\n",
    "L = np.max(np.abs(kernel_fourier)) # Ceci est la plus grande valeur propre de A.T @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Soit $b$ l'image précédemment importée. Calculer $Ab$, et afficher le résultat avec `imshow`. Faire de même avec $A^4b$. Que constatez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2)** Comment se convaincre que cette application `flou` est linéaire? Très simple: générer deux matrices aléatoires $X$ et $Y$ dans $\\Mm_{128,128}(\\RR)$, et vérifier que $A(X+Y)=AX + AY$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3)** Non seulement `flou` est linéaire, mais elle est en plus symétrique, c'est-à-dire que $A^*=A$. Pour s'en convaincre, il suffit de prendre deux matrices aléatoires $X$ et $Y$ et de vérifier que $\\langle AX,Y\\rangle = \\langle X,AY \\rangle$. On pourra utiliser la fonction `dotp(.,.)` qui calcule le produit scalaire entre deux vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1)** Adapter le code de la question **I.3.1)** pour coder une nouvelle fonction `defloutage`, qui:\n",
    "- prend en entrée une image floutée `b`, un nombre maximal d'itérations `itermax`\n",
    "- applique l'algorithme du gradient à pas constant à $\\Vert Ax-b \\Vert^2/2$, où $A$ est l'application de flou, en initialisant l'algorithme à zéro, et en prenant comme pas $\\rho = 1.9/L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defloutage(b, itermax):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return x      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2)** Tester cette fonction avec `itermax=2000`. Comparer le résultat avec la photo floutée originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(dpi=100)\n",
    "_ = plt.subplot(1,2,1)\n",
    "imshow(# l'image floutée\n",
    "_ = plt.subplot(1,2,2)\n",
    "imshow(# l'image obtenue par l'algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Algorithme du Gradient Stochastique pour du not-so-big-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm, svd\n",
    "from numpy.random import randn, randint\n",
    "import random\n",
    "# Seed for np.random\n",
    "np.random.seed(seed=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'intéresse ici à la minimisation d'une fonction logistique (régularisée):\n",
    "\n",
    "$$ f(w) = \\frac{1}{m} \\sum\\limits_{i=1}^m \\ln \\left( 1 + e^{y_i \\langle \\phi_i, w \\rangle} \\right)  + \\frac{\\mu}{2} \\Vert w \\Vert^2, $$\n",
    "\n",
    "où $\\phi_i \\in \\R^n$, $y_i \\in \\{\\pm 1 \\}$ et $\\mu >0$. Par la suite, pour plus de lisibilité on notera `nb_data` au lieu de $m$, et `dim_data` au lieu de $n$.\n",
    "\n",
    "**Dans toute la suite**, et à moins que le contraire soit précisé, tous les vecteurs devront être écrits sous la forme de vecteurs 1D : `array([1, 2, 3,...])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_logistic(A, y, mu, X):\n",
    "    # X est une suite de vecteurs de la forme dim_data x nb_points\n",
    "    # X peut également être simplement un seul 1D vecteur de taille dim_data\n",
    "    # La fonction renvoie un vecteur \"value\" de longueur nb_points\n",
    "    # où chaque composante value[i] vaut f(X[:,i])\n",
    "    nb_data = A.shape[0]\n",
    "    dim_data = A.shape[1]\n",
    "    if X.ndim == 1:\n",
    "        value = 0\n",
    "    else:      \n",
    "        value = np.zeros(X.shape[1])\n",
    "    for i in range(nb_data):\n",
    "        r = np.log(1 + np.exp(-(A[i,:]@X)*y[i]))\n",
    "        value = value + r \n",
    "    return (value/nb_data) + (mu/2)*(np.sum(X*X, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle si besoin que \n",
    "\n",
    "$$ \\nabla f_i(w) = \\frac{y_i e^{y_i \\langle \\phi_i, w \\rangle}}{1 + e^{y_i \\langle \\phi_i, w \\rangle}} \\phi_i + \\mu w$$\n",
    "\n",
    "L'objectif ici est d'étudier le comportement de SGD sur un exemple simple, et de regarder si les bornes que l'on a vu en cours sont pertinentes (spoiler: oui). On va notamment s'intéresser à l'influence de la taille du batch et du choix du pas. Ici le sampling sera uniforme.\n",
    "\n",
    "Afin de pouvoir visualiser par la suite les résultats des expériences, on supposera que les features sont de dimension $2$ ($n=2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1)** Générer un jeu de features alétoires, sous la forme d'une matrice aléatoire $A$ de taille `nb_data`x2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"https://cloud.math.univ-paris-diderot.fr/apps/files_sharing/publicpreview/Pt63MJCaF9TXbaw?x=2048&y=476&a=true&file=features.png&scalingup=0\" width=\"400\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'instant on prendra `nb_data=1000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2)** Générer un jeu de labels, sous la forme d'un vecteur $y$ aléatoire de taille `nb_data` à valeurs dans $\\{ \\pm 1 \\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1)** Définir une fonction `grad_logistic(A, y, mu, w, i)` qui prend en entrée une matrice de features `A`, un vecteur de labels `y`, le paramètre $\\mu$, un vecteur `w` dans $\\R^2$, et un entier `i` ; et qui renvoie $\\nabla f_i(w)$. On rappelle que les features correspondent aux lignes de `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_logistic(A, y, mu, w, i):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2)** Définir une fonction `grad_batch_logistic(A, y, mu, w, batch)` qui prend en entrée une matrice de features `A`, un vecteur de labels `y`, le paramètre $\\mu$,  un vecteur `w` dans $\\R^2$, et une *liste* `batch` d'entiers ; et qui renvoie $$\\frac{1}{\\vert batch \\vert}\\sum\\limits_{i \\in batch}\\nabla f_i(w).$$\n",
    "\n",
    "On rappelle que l'on peut faire une boucle for sur une liste donnée : `for i in nom_de_la_liste:` ; et que la longueur d'une liste s'obtient avec `len(nom_de_la_liste)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_batch_logistic(A, y, mu, w, batch):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3)** Définir une fonction `Lipschitz_batch(A, mu, batch_size)` qui prend en entrée une matrice de features `A`, la constante `mu`, une taille de batch `batch_size` ; et qui renvoie $\\Ll$, la constante de smoothness par rapport au sampling vu en cours. On rappelle si besoin que dans notre cadre de mini-batch sampling, on a (avec `m=nb_data` et `b=batch_size`):\n",
    "$$\\Ll \\leq \\frac{(b-1)m}{(m-1)b} \\bar L + \\frac{m-b}{b(m-1)} L_{max},$$ \n",
    "où $L_{max} = \\max_i L_i$, $L_i = Lip(\\nabla f_i)$ et $\\bar L = (1/m)\\sum_i Lip(\\nabla f_i)$. \n",
    "\n",
    "**NB:**  Vous pourrez consulter le TD au sujet du calcul de $L_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on pensera à ne pas oublier mu\n",
    "def Lipschitz_batch(A, mu, batch_size):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0)** Définir une fonction `SGD(A, b, mu, iter_max, batch_size, stepsize_factor, starting_point)` qui applique l'algorithme du gradient stochastique au problème de régréssion logistique présenté au début de cette section:\n",
    "- Le pas de l'algorithme sera constant, et égal à `stepsize_factor`$/\\Ll$.\n",
    "- A chaque itération, on tirera au hasard et uniformément une liste de taille `batch_size` parmi $\\{0,\\cdots,m-1\\}$, avec la commande `random.sample(range(m), batch_size)`\n",
    "- L'algorithme fera `iter_max` itérations.\n",
    "- L'algorithme commencera avec `starting_point` comme premier itéré.\n",
    "- L'algorithme renverra deux variables en sortie:\n",
    "    - Le dernier itéré de la suite (un vecteur 1D)\n",
    "    - Une matrice `iterates` de taille 2 x `iter_max`, qui contiendra (en colonnes) la suite des vecteurs $w^k$ générés par l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(A, y, mu, iter_max, batch_size, stepsize_factor, starting_point):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return w, iterates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1)** Par la suite, on aura besoin d'avoir accès à la solution \"exacte\" du problème, qu'on notera `w_sol`. Pour la calculer on utilisera `SGD` avec un batch complet (c'est à dire qu'on fera en fait l'algorithme du gradient). On prendra `stepsize_factor` (à vous de le choisir!), `starting_point=np.zeros(2)` et `iter_max` le plus grand possible sans que l'algo ne tourne plus d'une minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2)** S'assurer que `w_sol` est bien un minimiseur (et donc que votre algorithme marche à peu près) en vérifiant que $\\nabla f(w_{sol}) \\simeq 0$. Vous pourrez calculer astucieusement $\\nabla f$ en utilisant la fonction `grad_batch_logistic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3)** Définir `inf_f` comme étant l'infimum de $f$, à l'aide de `w_sol` et la fonction `loss_logistic` qu'on vous a donné au début de cette section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** On souhaite comparer la vitesse de convergence de la méthode, en fonction du choix de la taille de batch. Pour cela on va faire tourner l'algorithme dans 3 régimes, correspondant à trois tailles de batch: `1` (le single element sampling), `nb_data` (full batch), et `minibatch=5` (intermédiaire).\n",
    "\n",
    "**4.1)**  Utiliser l'algorithme pour chaque taille de batch. Pour chacun d'entre eux on utilisera les mêmes paramètres :`iter_max` $\\sim$ 100 (à vous de choisir), `stepsize_factor` = 0.5 et un même point initial aléatoire, par exemple `10*randn(2)` \n",
    "\n",
    "**NB:** on évite de prendre 0 comme point initial car on est dans un cadre assez spécifique où, même si `A` et `y` sont aléatoires, la solution du problème est toujours concentrée autour de 0. Ce serait tricher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2)** En utilisant la liste des itérés produite par SGD, et la fonction `loss_logistic`, tracer $f(x^k) - \\inf f$ pour chacun des trois régimes. Pour tracer une courbe il suffira d'utiliser `plt.plot(iterations, vecteur_des_valeurs)`, avec `iterations=np.arange(iter_max)` . Comparer les courbes et commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = np.arange(iter_max)\n",
    "_ = plt.figure(dpi=100, figsize=(12, 4))\n",
    "_ = plt.yscale(\"log\") # Pour avoir une échelle logarithmique\n",
    "_ = plt.plot # full batch\n",
    "_ = plt.plot # mini batch\n",
    "_ = plt.plot # single element\n",
    "_ = plt.legend(['full batch','mini batch','single elt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3)** A la question précédente on a tracé la courbe de $f(x^k) - \\inf f$. Or comparer ces courbes en tout $k$ est injuste : une itération pour la méthode avec un full batch coute `nb_data` fois plus cher qu'une itération avec un batch de taille 1.\n",
    "\n",
    "Reprendre donc les deux questions précédentes, mais cette fois-ci on va pour chaque algorithme utiliser un nombre différent d'itérations, de telle façon que chaque algorithme ne passe que `10` fois sur les données, exactement. On tracera alors, pour chaque régime, une courbe *constante par morceaux*: le vecteur des abscisses `iterations` devra être modifié en fonction de la taille du batch. \n",
    "\n",
    "Commenter les courbes que vous obtenez, en faisant le lien notamment avec les résultats du cours. Pensez-vous que le problème que l'on résoud est \"facile\"? Avec quel paramètre pourriez-vous jouer pour changer cela?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fonction qui pourra vous être utile pour transformer des vecteurs en vecteurs constants par morceaux : testez-là sur np.arange(10) !\n",
    "def dilater(x, factor):\n",
    "    # dilates x by a factor making it longer and therefore constant by parts\n",
    "    y = np.zeros(x.shape[0]*factor)\n",
    "    for k in range(x.shape[0]):\n",
    "        y[k*factor:(k+1)*factor] = x[k]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** On va maintenant essayer de visualiser la trajectoires des *itérés* de la suite générée par SGD dans le plan (c'est pour cela qu'on s'est fixés `dim_data=2`). Ci-dessous, une fonction `plot_levelset` qui permet de tracer les itérés d'une suite, ainsi que d'afficher les courbes de niveau de la fonction $f$. \n",
    "\n",
    "**NB:** ne pas modifier le code ci-dessous\n",
    "\n",
    "**NB:** Si vous n'avez pas respéecté la consigne d'écrire les vecteurs comme des 1D-arrays, vous aurez ici des problèmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(X, crop=None, option=None):\n",
    "    # Given a 2D sequence X of size 2 x nb_iter\n",
    "    # returns a box=[mx,Mx,my,mY] in which it belongs (for display purposes)\n",
    "    if option is \"square\":\n",
    "        min_x = np.min(X); max_x = np.max(X); min_y = min_x; max_y = max_x;\n",
    "    else:\n",
    "        min_x = np.min(X[0,:]); max_x = np.max(X[0,:]); min_y = np.min(X[1,:]); max_y = np.max(X[1,:]);\n",
    "    if crop is None: crop = 0.31\n",
    "    mx = min_x - crop * (max_x-min_x); Mx = max_x + crop * (max_x-min_x);\n",
    "    my = min_y - crop * (max_y-min_y); My = max_y + crop * (max_y-min_y);\n",
    "    return [mx, Mx, my, My]\n",
    "\n",
    "def plot_levelset(A, b, mu, iterates, box=None):\n",
    "    # Given the function f(A,b) et a 2D sequence of points (X,Y)\n",
    "    # plots the contour of the function and the sequence of iterates of size 2 x nb_iter\n",
    "    # We do it within a box=[mx,Mx,my,mY]\n",
    "    if box is None: box = get_box(iterates)\n",
    "    [mx, Mx, my, My] = box\n",
    "    x = np.linspace(mx, Mx, 50)\n",
    "    y = np.linspace(my, My, 50)\n",
    "    X_grid, Y_grid = np.meshgrid(x, y)\n",
    "    grid = np.zeros((2,50*50))\n",
    "    grid[0,:] = X_grid.reshape(50*50)\n",
    "    grid[1,:] = Y_grid.reshape(50*50)\n",
    "    Z = loss_logistic(A, b, mu, grid)\n",
    "    Z_grid = Z.reshape(50,50)\n",
    "    _=plt.contour(X_grid, Y_grid, Z_grid, colors='black') # level sets\n",
    "    _=plt.scatter(iterates[0,0],iterates[1,0], facecolors='none', edgecolors='r', s=100) # strating point\n",
    "    _=plt.scatter(iterates[0,:],iterates[1,:], facecolors='none', edgecolors='b') # trajectory\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "def plot_solution(w_sol, radius=None):\n",
    "    if radius is None: radius=0\n",
    "    ball = plt.Circle((w_sol[0], w_sol[1]), radius=radius, color='r', fill=False)\n",
    "    plt.gcf().gca().add_artist(ball) # the circle\n",
    "    _=plt.scatter(w_sol[0], w_sol[1], marker='*', edgecolors='r', s=100) # solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on va un peu changer les paramètres du problème. \n",
    "\n",
    "Générer à nouveau, comme pour la question **1)**, un jeu de données `A,y` avec `nb_data = 20`. On prendra un nouveau `mu=0.01` On pensera à égalment calculer à nouveau `w_sol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1)** Faire tourner l'algorithme avec les paramètres de votre choix, et utiliser `plot_levelset(A, y, mu, iterates)` pour visualiser la suite des itérés qu'elle génère. On pourra également utiliser `plot_solution(w_sol)` pour afficher la solution du problème (pour avoir un \"joli\" point de départ, je conseille de le prendre à distance raisonable de l'origine). N'hésitez pas a tester différents paramètres et points initiaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2)** Faire varier la taille du batch, et la valeur de `stepsize_factor`, et décrivez ce que vous observez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3)** D'après le cours, on sait qu'après un grand nombre d'itérations, la suite va (en moyenne) être contenue dans une boule centrée en `w_sol` et de rayon `r`, donné par\n",
    "\n",
    "$$ r = \\sqrt{\\frac{2\\sigma^2\\lambda}{\\mu}} \\quad \\text{ où } \\sigma^2 = \\E_S\\left[ \\Vert \\nabla f_S(w_{sol}) \\Vert^2 \\right] \\text{ et } \\lambda \\text{ est le pas de l'algorithme}. $$\n",
    "\n",
    "Par ailleurs, il est possible de montrer que  $\\sigma^2 = \\frac{m-b}{b(m-1)} \\frac{1}{m}\\sum\\limits_{i=1}^m \\Vert \\nabla f_i(w_{sol}) \\Vert^2$, où ici  $b$ est la taille du batch et $m$ le nombre de données (cf. [Proposition 3.10.iii ici](https://arxiv.org/pdf/1901.09401.pdf)).\n",
    "\n",
    "Définir une fonction `expected_radius(A, y, mu, w_sol, batch_size, stepsize_factor)` qui renvoie la valeur de ce rayon $r$ en fonction des paramètres du problème et de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_radius(A, y, mu, w_sol, batch_size, stepsize_factor):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4)** Reprendre la question **5.1)** en utilisant cette fois-ci `plot_solution(w_sol, rayon)`, en utilisant un rayon que vous calculerez avec la fonction précédente. \n",
    "\n",
    "Est-ce que le résultat est fidèle à la théorie? Discuter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:** Un widget interactif pour montrer la convergence des itérés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_max = 1000\n",
    "mu = 0.2\n",
    "starting_point = 3*randn(2)\n",
    "stepsize_factor_max = 1\n",
    "\n",
    "[_, X_messy] = SGD(A, y, mu, iter_max*10, \n",
    "                            batch_size=1, stepsize_factor=stepsize_factor_max,  starting_point=starting_point)\n",
    "box = get_box(X_messy, crop=0.2, option=\"square\")\n",
    "[wsol, X_GD] = SGD(A, y, mu, iter_max, \n",
    "                           batch_size=nb_data, stepsize_factor=1.9,  starting_point=starting_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widget_iterates(stepsize_factor, batch_size):\n",
    "    [w, iterates] = SGD(A, y, mu, iter_max, \n",
    "                               batch_size=batch_size, \n",
    "                               stepsize_factor=stepsize_factor, \n",
    "                               starting_point=starting_point)\n",
    "    \n",
    "    comp = int(iter_max*batch_size/nb_data)\n",
    "    # We plot many things\n",
    "    _=plt.figure(dpi=100, figsize=(12, 4))\n",
    "    \n",
    "    rayon = expected_radius(A, y, mu, wsol, batch_size, stepsize_factor)\n",
    "    plot_levelset(A, y, mu, iterates, box=box)\n",
    "    plot_solution(wsol, rayon)\n",
    "    \n",
    "    \n",
    "    \"\"\"_ = plt.title(r\"Trajectoire de SGD, fonction logistique.\" + \n",
    "                  \"\\n  Pas relatif: \" + str(stepsize_factor) + \", batch size: \" + str(batch_size) + \n",
    "                 \"\\n Complexité: \" + str(iter_max*batch_size))\n",
    "    \"\"\"\n",
    "    #plt.gcf().gca().titleweight=\"light\"\n",
    "    _ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 120 # To be changed depending on screen resolution\n",
    "interactive(widget_iterates, \n",
    "            stepsize_factor=widgets.FloatSlider(min=0.01, max=stepsize_factor_max, step=0.01, value=0.5), \n",
    "            batch_size=widgets.IntSlider(min=1, max=nb_data, step=1, value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
